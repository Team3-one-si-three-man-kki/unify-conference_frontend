// src/hooks/useMediaPipe.js
import { useState, useEffect, useRef } from 'react';
import { useSessionStore } from '../store/session/sessionStore';

export const useMediaPipe = (videoRef, canvasRef, enabled = true) => {
    const { roomClient, setIsDrowsy, setIsAbsent } = useSessionStore();
    const visionModuleRef = useRef(null);
    const filesetResolverRef = useRef(null); // ğŸ”½ FilesetResolverë¥¼ ì €ì¥í•  ref ì¶”ê°€
    const [isMediaPipeReady, setIsMediaPipeReady] = useState(false); // ğŸ”½ ëª¨ë“ˆê³¼ ë¦¬ì¡¸ë²„ ë¡œë”© ì™„ë£Œë¥¼ ì•Œë¦¬ëŠ” state
    const [faceLandmarker, setFaceLandmarker] = useState(null);
    const animationFrameIdRef = useRef(null);
    const drowsinessTimeoutRef = useRef(null);
    const absenceTimeoutRef = useRef(null);

    // Effect 1: MediaPipe ëª¨ë“ˆê³¼ FilesetResolverë¥¼ ìµœì´ˆ 1íšŒë§Œ ë¡œë“œí•©ë‹ˆë‹¤.
    useEffect(() => {
        const loadMediaPipe = async () => {
            if (visionModuleRef.current) return; // ì´ë¯¸ ë¡œë“œë˜ì—ˆìœ¼ë©´ ì¤‘ë‹¨

            try {
                const vision = await import('@mediapipe/tasks-vision');
                visionModuleRef.current = vision;
                console.log("useMediaPipe: Vision module loaded ONCE.");

                const { FilesetResolver } = vision;
                const resolver = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm");
                filesetResolverRef.current = resolver; // refì— ì €ì¥
                console.log("useMediaPipe: FilesetResolver created ONCE.");

                setIsMediaPipeReady(true); // ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ìŒì„ ì•Œë¦¼
            } catch (error) {
                console.error("Failed to load MediaPipe dependencies:", error);
            }
        };
        loadMediaPipe();
    }, []); // ë§ˆìš´íŠ¸ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰

    // Effect 2: 'enabled'ì™€ 'isMediaPipeReady' ìƒíƒœì— ë”°ë¼ FaceLandmarker ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    useEffect(() => {
        if (!enabled || !isMediaPipeReady) {
            if (faceLandmarker) {
                faceLandmarker.close();
                setFaceLandmarker(null);
                console.log("useMediaPipe: FaceLandmarker instance closed.");
            }
            return;
        }

        let isCancelled = false;
        const initializeFaceLandmarker = async () => {
            if (faceLandmarker) return; // ì´ë¯¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ì¤‘ë‹¨

            try {
                const { FaceLandmarker } = visionModuleRef.current;
                const newLandmarker = await FaceLandmarker.createFromOptions(filesetResolverRef.current, { // ì €ì¥ëœ ë¦¬ì¡¸ë²„ ì‚¬ìš©
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                        delegate: "GPU"
                    },
                    outputFaceBlendshapes: true, runningMode: "VIDEO", numFaces: 1
                });

                if (!isCancelled) {
                    setFaceLandmarker(newLandmarker);
                    console.log("useMediaPipe: FaceLandmarker instance created.");
                } else {
                    newLandmarker.close();
                }
            } catch (error) {
                console.error("Failed to initialize FaceLandmarker:", error);
            }
        };

        initializeFaceLandmarker();

        return () => {
            isCancelled = true;
            // enabledê°€ falseê°€ ë  ë•Œ landmarkerë¥¼ ì •ë¦¬í•˜ëŠ” ë¡œì§ì€ effect ì‹œì‘ ë¶€ë¶„ì—ì„œ ì²˜ë¦¬
        };
    }, [enabled, isMediaPipeReady]); // 'enabled' ìƒíƒœ ë˜ëŠ” ì¤€ë¹„ ìƒíƒœê°€ ë°”ë€” ë•Œ ì‹¤í–‰

    // Effect 3: ì‹¤ì œ ì–¼êµ´ ê°ì§€ ë° ë Œë”ë§ ë¡œì§ (ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼)
    useEffect(() => {
        const video = videoRef.current;
        const canvas = canvasRef.current;
        // ğŸ”½ visionModule ëŒ€ì‹  isMediaPipeReady, visionModuleRef.current ì‚¬ìš©
        if (!enabled || !faceLandmarker || !isMediaPipeReady || !video || !canvas || video.readyState < 3) {
            if (animationFrameIdRef.current) cancelAnimationFrame(animationFrameIdRef.current);
            return;
        }

        const { DrawingUtils, FaceLandmarker: FL } = visionModuleRef.current;
        const context = canvas.getContext('2d');
        const drawingUtils = new DrawingUtils(context);
        let lastVideoTime = -1;

        const detectAndRender = () => {
            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                const results = faceLandmarker.detectForVideo(video, performance.now());

                context.clearRect(0, 0, canvas.width, canvas.height);
                if (results.faceLandmarks) {
                    for (const landmarks of results.faceLandmarks) {
                        drawingUtils.drawConnectors(landmarks, FL.FACE_LANDMARKS_TESSELATION, { color: "#C0C0C070", lineWidth: 1 });
                    }
                }

                const currentSessionState = useSessionStore.getState();
                if (results.faceLandmarks.length > 0) {
                    if (currentSessionState.isAbsent) {
                        setIsAbsent(false);
                        if (absenceTimeoutRef.current) clearTimeout(absenceTimeoutRef.current);
                        absenceTimeoutRef.current = setTimeout(() => {
                            roomClient?.sendPeerStatus({ isAbsent: false, time: performance.now() });
                        }, 500);
                    }

                    const blendshapes = results.faceBlendshapes[0]?.categories || [];
                    const eyeBlinkLeft = blendshapes.find(s => s.categoryName === 'eyeBlinkLeft')?.score || 0;
                    const eyeBlinkRight = blendshapes.find(s => s.categoryName === 'eyeBlinkRight')?.score || 0;
                    const isCurrentlyDrowsy = eyeBlinkLeft > 0.4 && eyeBlinkRight > 0.4;

                    if (isCurrentlyDrowsy !== currentSessionState.isDrowsy) {
                        setIsDrowsy(isCurrentlyDrowsy);
                        if (drowsinessTimeoutRef.current) clearTimeout(drowsinessTimeoutRef.current);
                        drowsinessTimeoutRef.current = setTimeout(() => {
                            roomClient?.sendPeerStatus({ isDrowsy: isCurrentlyDrowsy, time: performance.now() });
                        }, 500);
                    }
                } else {
                    if (!currentSessionState.isAbsent) {
                        setIsAbsent(true);
                        if (absenceTimeoutRef.current) clearTimeout(absenceTimeoutRef.current);
                        absenceTimeoutRef.current = setTimeout(() => {
                            roomClient?.sendPeerStatus({ isAbsent: true, time: performance.now() });
                        }, 500);
                    }
                }
            }
            animationFrameIdRef.current = requestAnimationFrame(detectAndRender);
        };

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        detectAndRender();

        return () => {
            if (animationFrameIdRef.current) cancelAnimationFrame(animationFrameIdRef.current);
            if (drowsinessTimeoutRef.current) clearTimeout(drowsinessTimeoutRef.current);
            if (absenceTimeoutRef.current) clearTimeout(absenceTimeoutRef.current);
        };
    }, [faceLandmarker, enabled, isMediaPipeReady, videoRef, canvasRef, roomClient, setIsDrowsy, setIsAbsent]); // ğŸ”½ ì˜ì¡´ì„± ë°°ì—´ ìˆ˜ì •
};
